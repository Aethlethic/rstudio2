---
title: '산업공학특론I_9주차_다중회귀분석_실습'
author: 'Munwon Lim'
date: '5/1/2024'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=9, fig.height=9)
```

<br>
<br>
<br>



## [데이터 분석]

(https://www.kaggle.com/datasets/rukenmissonnier/manufacturing-data-for-polynomial-regression?resource=download)

다양한 공정 환경과 제품 품질 간의 관계를 탐색하기 위한 데이터셋

공정 조건을 나타내는 변수와 제조된 항목의 품질 등급을 나타내는 변수를 모두 포함

* TemperatureC: 제조 공정 중 측정된 섭씨 온도
* PressurekPa: 제조 공정 중 가해진 압력을 킬로파스칼 (kPa) 단위로 측정
* TemperaturexPressure: 온도와 압력 사이의 상호 작용, 두 공정 변수의 결합된 영향을 고려
* MaterialFusionMetric: 온도의 제곱과 압력의 세제곱의 합으로 계산된 파생 메트릭 - 제조 공정 중 재료 융합 관련 측정값
* MaterialTransformationMetric: 온도의 세제곱에서 압력의 제곱을 뺀 것으로 계산된 다른 파생 메트릭 - 재료 변형 역학 관련 측정값
* Quality Rating: 생산된 항목의 전체 품질 등급으로, 최종 제품의 품질을 측정하는 지표

<br>
<br>
<br>

### 1. 데이터 탐색 (EDA) 및 전처리
```{r eda}

# 데이터 로드 및 요약
list()
dat <- read.csv('산업공학특론I_9주차_실습 데이터.csv')
head(dat)
# 데이터 전처리
colnames(dat) <- gsub('[.]','_',colnames(dat))
summary(dat)

# 학습, 테스트셋 분할
set.seed(0)

trainidx <- sample(1:nrow(dat), 0.8*nrow(dat))
length(trainidx)

train <- dat[trainidx, ]
test <- dat[-trainidx, ]

# 데이터 시각화
plot(train)

```

<br>

### 2. 상관분석
```{r correlation}

library(corrplot)

# 상관계수 테이블 생성
corr <- cor(train, method = 'pearson')

# 상관계수 테이블 시각화
col <- colorRampPalette(c('red','blue'))
corrplot(corr, method = 'color', col = col(200), type = 'upper', addCoef.col = 'black')

```

<br>

### 3. 다중회귀분석

```{r regression}

# 다중회귀모형 수립
# 1) CV 수행 X
colnames(dat)
reg <- lm(Quality_Rating ~ ., data = train)
summary(reg)

# 2) CV 수행 O
install.packages('caret')
library(caret)

train_cv <- trainControl(method= 'cv', number= 10)

reg_cv <- train(Quality_Rating ~ ., data = train, method = 'lm',
                trControl= train_cv)

summary(reg_cv)
# 모델 수립 결과

 ## CV 수행 한거랑 안한거랑 큰 차이가 없음음

```


<br>

### 4. 변수선택법

```{r variableselection}

# 변수선택법 시행
# 1) CV 수행 X
reg_setp1 <- step(reg, direction = 'forward') #전전선택법
reg_setp2 <- step(reg, direction = 'backward') #후진제거법
reg_setp3 <- step(reg, direction = 'both') #단계적선택법

# 2) CV 수행 O
reg_step1_cv <- train(Quality_Rating ~ ., data = train, method = 'glmStepAIC',
                trControl= train_cv, direction='forward')
reg_step2_cv <- train(Quality_Rating ~ ., data = train, method = 'glmStepAIC',
                trControl= train_cv, direction='backward')
reg_step3_cv <- train(Quality_Rating ~ ., data = train, method = 'glmStepAIC',
                trControl= train_cv, direction='both')
                



# 모델 수립 결과
summary(reg_setp1) #reg과 동일
summary(reg_setp2) 
summary(reg_setp3) #reg_step2와 동일

summary(reg_step1_cv) 
summary(reg_step2_cv) 
summary(reg_step3_cv)
```


<br>

### 5. 정규화 회귀분석

```{r regularization}
install.packages('glmnet')
library(glmnet)

# 정규화 회귀모형 수립
# 1) CV 수행 X
x <- as.matrix(train[,1:5]); y<- as.matrix(train[,6])
#Lasso = L1, Ridge=L2, Elastic=both
glmnet(x,y,alpha)

lasso <- glmnet(x,y,alpha=1)
ridge <- glmnet(x,y,alpha=0)
elastic <- glmnet(x,y,alpha=0.5)

par(mfrow=c(1,3))
plot(lasso, xvar = 'lambda')
legend('bottomright', legend=colnames(x), col=1:5, lty=1)
plot(ridge, xvar = 'lambda')
plot(elastic, xvar = 'lambda')
# 2) CV 수행 O

lasso_cv <- cv.glmnet(x,y,alpha=1)
ridge_cv <- cv.glmnet(x,y,alpha=0)
elastic_cv <- cv.glmnet(x,y,alpha=0.5)



# 모델 수립 결과
plot(lasso_cv)
plot(ridge_cv)
plot(elastic_cv)

coef(ridge_cv)
```

<br>

### 6. 모형 평가 

```{r evaluation}

# 적합결과 평가 (학습모형 대상, 정규화 회귀분석은 AIC 평가 불가능)

regeval <- function(regr){ # 기본 모델에 대한 평가 함수
  summ <- summary(reg)
  mse <- summ$sigma^2
  adjrsq <- summ$adj.r.sqaured
  aic <- AIC(reg)
  result <- c(mse, adjrsq, aic)
  names(result) <- c('MSE', 'AdjRsq', 'AIC')
  print(result)

}

regeval(reg)
regeval(reg_step2)

pred <- predict(lasso_cv, x)
sse <- sum((pred - y)^2)
ssr <- sum((pred - mean(y))^2)

mse <- sse/(nrow(x) - length(reg$coef))
adjrsq <- 1 - (nrwo(x)-1)/(nrow(x) - length(reg$coef)) * ssr/sst
print(c(mse, adjrsq))


# 예측력 평가 (테스트셋 대상)
install.packages('Metrics')
library(Metrics)

#reg
pred_reg <- predict(reg, test)

regresult<- c(mae(pred_reg, test$Quality_Rating),
              mse(pred_reg, test$Quality_Rating),
              rmse(pred_reg, test$Quality_Rating))
#reg_step2
pred_reg2 <- predict(reg, test)

regresult2<- c(mae(pred_reg2, test$Quality_Rating),
              mse(pred_reg2, test$Quality_Rating),
              rmse(pred_reg2, test$Quality_Rating))
#lasso_cv
newx <- as.matrix(test[,1:5])
pred_lasso <- predict(lasso, newx)
regresult3<- c(mae(pred_lasso, test$Quality_Rating),
              mse(pred_lasso, test$Quality_Rating),
              rmse(pred_lasso, test$Quality_Rating))

rbind(regresult, regresult2, regresult3)





#ridge_cv

#elastic_cv

```
